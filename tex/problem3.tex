\begin{problem}[A\&P 4.17]
  Collocation at Gaussian points is an implicit, expensive method. An
alternative idea is to use an explicit Runge-Kutta method, orthogonalizing $U$ at the end of each time step. Consider a method of the form
  \[
    \mb y_n = \mb y_{n-1} + h \mb \psi(t_{n-1}, \mb y_{n-1}, h)
  \]
  for which the matrix $U(t)$ is written as an $m^2$-length vector of unknowns. Since the result of this step is not necessarily an orthogonal matrix, a step of this method starting with an orthogonal $U_{n-1}$ approximating $U(t_{n-1})$ consists of two phases:
  \begin{align*}
    \hat{U}_n &= U_{n-1} + h \psi(t_{n-1}, U_{n-1}, h), \\
    \hat{U}_n &= U_n R_n,
  \end{align*}
  where $U_n R_n$ is a $QR$ decomposition of $U_n$. The orthogonal matrix $U_n$ is then the projection of the result of the Runge-Kutta step onto the invariant manifold, and it is taken as the end result of the step.
  
  Write a program which carries out this algorithm using the classical fourth-order Runge-Kutta method. Try your program on the problem
  \begin{align*}
    U' = \omega
    \begin{pmatrix}
      0 & 1 \\
      -1 & 0
    \end{pmatrix}
    U,
  \end{align*}
  whose exact solution is the reflection matrix
  \[
    U(t) = 
    \begin{pmatrix}
      \cos \omega t & \sin \omega t \\
      -\sin \omega t & \cos \omega t
    \end{pmatrix}
  \]
  for various values of $w$, $h$, and $b$. What are your conclusions?
\end{problem}

\FloatBarrier

\begin{solution}
  Write 
  \[
    U = 
    \begin{pmatrix}
      y_1(t) & y_2(t) \\
      y_3(t) & y_4(t)
    \end{pmatrix}.
  \]
  Then we have 
  \begin{align*}
    \begin{pmatrix}
      y_1 & y_2 \\
      y_3 & y_4
    \end{pmatrix}' = 
    \omega
    \begin{pmatrix}
      0 & 1 \\
      -1 & 0
    \end{pmatrix}
    \begin{pmatrix}
      y_1 & y_2 \\
      y_3 & y_4
    \end{pmatrix}
  \end{align*}
  or 
  \begin{align*}
    \begin{pmatrix}
      y_1 & y_2 \\
      y_3 & y_4
    \end{pmatrix}' = 
    \omega
    \begin{pmatrix}
      y_3 & y_4 \\
      - y_1 & - y_2 
    \end{pmatrix}.
  \end{align*}
  Finally, in vector form we have
  \[
    \begin{pmatrix}
      y_1 \\ y_2 \\ y_3 \\ y_4
    \end{pmatrix}' = 
    \omega
    \begin{pmatrix}
      y_3 \\ y_4 \\ - y_1 \\ - y_2
    \end{pmatrix}.
  \]
  
  Since the built in MATLAB function for computing QR factorizations does not always yield the closest $Q$ to the original matrix, we write an alternative using the Gram-Schmidt process. See \texttt{matlab/problem3/qr2.m}.
  
  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.32\textwidth]{images/03_1_1.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_1_2.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_1_3.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_2_1.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_2_2.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_2_3.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_3_1.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_3_2.pdf}
    \includegraphics[width=0.32\textwidth]{images/03_3_3.pdf}
    \caption{Orthogonalization method for varying $\omega$, $h$}
    \label{F:03}
  \end{figure}

  Figure \ref{F:03} shows the solution in phase space for this method with varying values of $h$ and $\omega$. For each image, $b$ was taken to be $10 \pi/\omega$. This yields 5 rotations of the system. Immediately we see that some of the images coincide. Specifically
  \begin{align*}
    &\{h = 0.5, \omega = 0.5\}, \{h = 0.25, \omega = 1\}, \\
    \text{and } &\{h = 1, \omega = 0.5\}, \{h = 0.5, \omega = 1\}, \{h = 0.25, \omega = 2\}, \\
    \text{and } &\{h = 1, \omega = 1\}, \{h = 0.5, \omega = 2\}.
  \end{align*}
  
  From this, it seems that the phase space solution depends only on $h \omega$. We make sense of this by looking at the exact solution,
  \[
    U(t) = 
    \begin{pmatrix}
      \cos \omega t & \sin \omega t \\
      -\sin \omega t & \cos \omega t
    \end{pmatrix}.
  \]
  This is a rotation matrix, and the speed of rotation is determined by $\omega$. For larger $\omega$, the rotation is faster. Intuitively we would expect to have to use more steps to get the same results when $\omega$ is high. For example going from $\omega = 1$ to $\omega = 2$, we need twice as many steps to get the same result. In other words we need to cut $h$ in half.
  
  In this case, knowing the nature of the exact solution helps to determine which values of $h$ will be sufficient. 
\end{solution}